{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "796c9aab-eb05-4cc7-97b2-f45caf5a0d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to C:\\Users\\Nathan\n",
      "[nltk_data]     Hua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Nathan\n",
      "[nltk_data]     Hua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "39013a66-0e8e-422f-80af-2ffb4a1540de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from txt\n",
    "def read_data(set_name):\n",
    "    text_file_name  = set_name + \"_text.txt\"\n",
    "    label_file_name = set_name + \"_labels.txt\"\n",
    "    text_file = open(\"data/\" + text_file_name, \"r\", encoding=\"utf8\")\n",
    "    label_file = open(\"data/\" + label_file_name, \"r\", encoding=\"utf8\")\n",
    "    x = text_file.readlines()\n",
    "    y = label_file.readlines()\n",
    "    for i in range(len(y)): y[i] = y[i][0]\n",
    "    return pd.DataFrame(x, columns=[\"text\"]), pd.DataFrame(y, columns=[\"label\"])\n",
    "train_set_x, train_set_y = read_data(\"train\")\n",
    "val_set_x,   val_set_y   = read_data(\"val\")\n",
    "test_set_x,  test_set_y  = read_data(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "26b54ada-0928-4ad0-9604-8c570656faae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4583333333333333, 0.5416666666666666]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "additional_stopwords = [\".\", \",\", \"'s\", \"``\", \"''\", \"'\",\n",
    "                        \"n't\", \"%\", \"-\", \"$\", \"(\", \")\", \":\",\n",
    "                        \";\", \"@\", \"&\", \"'m\", \"user\", \"#\", \"!\",\n",
    "                        \"?\", \"...\", \"a\"]\n",
    "for sw in additional_stopwords: stopwords.add(sw)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def penn_to_wn(tag):\n",
    "    \"\"\"\n",
    "    Convert between the PennTreebank tags to simple Wordnet tags\n",
    "    \"\"\"\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return None\n",
    "\n",
    "# level 1-4: consider wn.VERB, wn.NOUN, wn.ADJ, wn.ADV\n",
    "# level len(consider_list): consider all\n",
    "consider_list = [wn.VERB, wn.NOUN, wn.ADJ, wn.ADV]\n",
    "def get_senti_score(sentence, level=len(consider_list)):\n",
    "    token = nltk.word_tokenize(sentence)\n",
    "    # remove stop words\n",
    "    index = len(token) - 1\n",
    "    while index >= 0:\n",
    "        if token[index] in stopwords:\n",
    "            token.pop(index)\n",
    "        index -= 1\n",
    "    after_tagging = nltk.pos_tag(token)\n",
    "    sentiment = 0.0\n",
    "    objective = 0.0\n",
    "    tokens_count = 0\n",
    "    for word, tag in after_tagging:\n",
    "        wn_tag = penn_to_wn(tag)\n",
    "        if level == len(consider_list):\n",
    "            if wn_tag not in consider_list: continue\n",
    "        else:\n",
    "            if wn_tag != consider_list[level]: continue\n",
    "\n",
    "        lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "        if not lemma: continue\n",
    "\n",
    "        synsets = list(swn.senti_synsets(lemma, pos=wn_tag))\n",
    "        if not synsets: continue\n",
    "\n",
    "        swn_synset = synsets[0]\n",
    "\n",
    "        sentiment += swn_synset.pos_score() - swn_synset.neg_score()\n",
    "        objective += swn_synset.obj_score()\n",
    "        tokens_count += 1\n",
    "    if tokens_count == 0: return [0,0]\n",
    "    return [sentiment / tokens_count, objective / tokens_count]\n",
    "get_senti_score(\"It was a really good day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "80273229-955d-426b-ab9a-3b5c6e3e59cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current level: 0\n",
      "precision_score: 0.31031458762862457\n",
      "recall_score: 0.364972303952805\n",
      "f1_score: 0.3331214785197157\n",
      "accuracy_score: 0.4613616776788279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan Hua\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current level: 1\n",
      "precision_score: 0.2985922637005483\n",
      "recall_score: 0.3438745775714042\n",
      "f1_score: 0.27188439819437876\n",
      "accuracy_score: 0.42229244469979893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan Hua\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current level: 2\n",
      "precision_score: 0.3268760540814391\n",
      "recall_score: 0.35327775038033193\n",
      "f1_score: 0.2709234849496997\n",
      "accuracy_score: 0.43263430048836543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan Hua\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current level: 3\n",
      "precision_score: 0.14823326630278655\n",
      "recall_score: 0.3333333333333333\n",
      "f1_score: 0.20520978325710879\n",
      "accuracy_score: 0.44469979890835964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan Hua\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current level: 4\n",
      "precision_score: 0.3326684444558497\n",
      "recall_score: 0.3667685297545497\n",
      "f1_score: 0.30379089161185097\n",
      "accuracy_score: 0.4527434645216892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan Hua\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Init SVC model\n",
    "svm_clf_category = sklearn.svm.SVC(kernel=\"linear\", gamma='auto')\n",
    "\n",
    "# loop to see every level output\n",
    "for level in range(len(consider_list) + 1):\n",
    "    # prepare data\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in train_set_x.index:\n",
    "        for sentence in nltk.tokenize.sent_tokenize(train_set_x.loc[i, \"text\"]):\n",
    "            x.append(get_senti_score(sentence, level))\n",
    "            y.append(train_set_y.loc[i, \"label\"])\n",
    "\n",
    "    # Train model\n",
    "    svm_clf_category.fit(np.asarray(x), np.asarray(y))\n",
    "\n",
    "    # test with val set\n",
    "    vx, vy = [], []\n",
    "    for i in val_set_x.index:\n",
    "        for sentence in nltk.tokenize.sent_tokenize(val_set_x.loc[i, \"text\"]):\n",
    "            vx.append(get_senti_score(sentence, level))\n",
    "            vy.append(val_set_y.loc[i, \"label\"])\n",
    "    predictions = svm_clf_category.predict(vx)\n",
    "    vy = np.asarray(vy)\n",
    "\n",
    "    print(\"Current level: \" + str(level))\n",
    "    print(\"precision_score: \" + str(precision_score(vy, predictions, average='macro')))\n",
    "    print(\"recall_score: \" + str(recall_score(vy, predictions, average='macro')))\n",
    "    print(\"f1_score: \" + str(f1_score(vy, predictions, average='macro')))\n",
    "    print(\"accuracy_score: \" + str(accuracy_score(vy, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8374e910-bd83-4aba-8b96-b9b5b94d3332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df21480f-fef6-417b-9082-826204d99f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a4f8a-a578-4980-b9b1-7093f03a7881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
