{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eacb044-d8f8-4806-a1fc-d5c844b9e4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Nathan\n",
      "[nltk_data]     Hua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Nathan\n",
      "[nltk_data]     Hua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Nathan\n",
      "[nltk_data]     Hua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Nathan\n",
      "[nltk_data]     Hua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import operator\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from matplotlib.pyplot import plot\n",
    "nltk.download('stopwords') # If needed\n",
    "nltk.download('punkt') # If needed\n",
    "nltk.download('wordnet') # If needed\n",
    "nltk.download('omw-1.4') # If needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1865868b-a1be-4246-821d-80a4a034be23",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8132ee23-6b2b-4a52-926b-0dec208e8112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label mapping declaration\n",
    "SENTIMENTAL_MAP = {\n",
    "    \"0\": \"negative\",\n",
    "    \"1\": \"neutral\",\n",
    "    \"2\": \"positive\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c2ffc6c-8cbd-482e-b80e-5e49d74a46a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for k in SENTIMENTAL_MAP.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aae7972-4885-4ede-a024-ce9a76145cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from txt\n",
    "def read_data(set_name):\n",
    "    text_file_name  = set_name + \"_text.txt\"\n",
    "    label_file_name = set_name + \"_labels.txt\"\n",
    "    text_file = open(\"data/\" + text_file_name, \"r\", encoding=\"utf8\")\n",
    "    label_file = open(\"data/\" + label_file_name, \"r\", encoding=\"utf8\")\n",
    "    x = text_file.readlines()\n",
    "    y = label_file.readlines()\n",
    "    for i in range(len(y)): y[i] = y[i][0]\n",
    "    return pd.DataFrame(x, columns=[\"text\"]), pd.DataFrame(y, columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89374b52-8776-4630-897a-0125680ae323",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x, train_set_y = read_data(\"train\")\n",
    "val_set_x,   val_set_y   = read_data(\"val\")\n",
    "test_set_x,  test_set_y  = read_data(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edb927e0-6502-49de-af82-9b3107e106e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45615, 1)\n",
      "(45615, 1)\n",
      "(2000, 1)\n",
      "(2000, 1)\n",
      "(12284, 1)\n",
      "(12284, 1)\n"
     ]
    }
   ],
   "source": [
    "print(str(train_set_x.shape))\n",
    "print(str(train_set_y.shape))\n",
    "print(str(val_set_x.shape))\n",
    "print(str(val_set_y.shape))\n",
    "print(str(test_set_x.shape))\n",
    "print(str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f6f4930-7e86-4601-9dbd-b1c3e3164785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omg this show is so predictable even for the 3rd ep. Rui En\\u2019s ex boyfriend was framed for murder probably\\u002c by the rich guy. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(val_set_x.loc[7, \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e70b08ca-4a2f-44f2-a0fe-d7a79141fd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",\n"
     ]
    }
   ],
   "source": [
    "#TODO: remove meaningless text, such as \"@user\" \"#sometagname\"\n",
    "#TODO: remove http links, such as \"https://t.co/4fPkSVlSDl\"\n",
    "#TODO: convert some unicode string to text, such as \"\\u2019\" => \"'\"\n",
    "test = u'\\u002c'\n",
    "print(str(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42029b18-4600-4e07-98bf-e7b8837e15b7",
   "metadata": {},
   "source": [
    "## initial feature and its train, val, test process\n",
    "### TODO: Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b85853b4-db7a-4a8a-a7f4-aee86894aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(vocab, text):\n",
    "    vector = np.zeros(len(vocab))\n",
    "    words = []\n",
    "    for sentence in nltk.tokenize.sent_tokenize(text):\n",
    "        for token in nltk.tokenize.word_tokenize(sentence):\n",
    "            words.append(lemmatizer.lemmatize(token).lower())\n",
    "    for i, word in enumerate(vocab):\n",
    "        if word in words:\n",
    "            vector[i] = words.count(word)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d838d07b-4028-4bc6-91dd-f7467f54b5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Initial Feature: n most frequent words of each label class and combining them together\n",
    "# define stopwords\n",
    "stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "additional_stopwords = [\".\", \",\", \"'s\", \"``\", \"''\", \"'\", \"n't\", \"%\", \"-\", \"$\", \"(\", \")\", \":\", \";\", \"@\", \"&\", \"'m\", \"user\", \"#\", \"!\", \"?\", \"...\"]\n",
    "for sw in additional_stopwords: stopwords.add(sw)\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "# Get Vocabulary\n",
    "vocabulary = []\n",
    "n = 100\n",
    "for label in SENTIMENTAL_MAP.keys():\n",
    "    print(train_set_y.loc[1, \"label\"])\n",
    "    # get texts with same label\n",
    "    temp_list = []\n",
    "    for i in train_set_x.index:\n",
    "        if train_set_y.loc[i, \"label\"] == label:\n",
    "            temp_list.append(train_set_x.loc[i, \"text\"])\n",
    "    \n",
    "    # get n most frequent words of this label class\n",
    "    dict_word_freq = {}\n",
    "    for text in temp_list:\n",
    "        for sentence in nltk.tokenize.sent_tokenize(text):\n",
    "            for token in nltk.tokenize.word_tokenize(sentence):\n",
    "                word = lemmatizer.lemmatize(token).lower()\n",
    "                if word in stopwords: continue\n",
    "                if word in dict_word_freq: dict_word_freq[word] += 1\n",
    "                else: dict_word_freq[word] = 1\n",
    "                \n",
    "    # sort and add first n words in sorted list to vocabulary\n",
    "    sorted_list = sorted(dict_word_freq.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    if n < len(sorted_list): sorted_list = sorted_list[:n]\n",
    "    for word, frequency in sorted_list:\n",
    "        if word not in vocabulary: vocabulary.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "919f9348-2d60-4158-b22b-1ad8747cd303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['may', 'tomorrow', 'wa', 'like', '1st', 'day', 'going', 'get', 'time', 'ha', 'sunday', '..', 'go', 'see', 'one', 'want', 'amp', '2nd', 'night', 'friday']\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8929636b-c6fb-46e2-a38e-1d8b45a0ad16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4ebfa73-83e6-4ae1-a5e0-b132f88ad653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data\n",
    "x, y = [], []\n",
    "for i in train_set_x.index:\n",
    "    x.append(get_vector(vocabulary, train_set_x.loc[i, \"text\"]))\n",
    "    y.append(train_set_y.loc[i, \"label\"])\n",
    "\n",
    "# Init and train model\n",
    "svm_clf_category = sklearn.svm.SVC(kernel=\"linear\", gamma='auto')\n",
    "svm_clf_category.fit(np.asarray(x), np.asarray(y))\n",
    "\n",
    "# test with val set\n",
    "x, y = [], []\n",
    "for i in val_set_x.index:\n",
    "    x.append(get_vector(vocabulary, val_set_x.loc[i, \"text\"]))\n",
    "    y.append(val_set_y.loc[i, \"label\"])\n",
    "predictions = svm_clf_category.predict(x)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5621a91-3036-4541-8cf4-c79c28aa59ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ce4e1d4-9dbc-46ce-ab95-359a4164fa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5968940682679603\n",
      "0.4229266396987916\n",
      "0.3907685423265885\n",
      "0.525\n"
     ]
    }
   ],
   "source": [
    "print(str(precision_score(y, predictions, average='macro')))\n",
    "print(str(recall_score(y, predictions, average='macro')))\n",
    "print(str(f1_score(y, predictions, average='macro')))\n",
    "print(str(accuracy_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a15b22f-815a-4e2f-8d65-bd9cb1fdde1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2376b16-21d1-4141-a34b-e700b2255bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83f6e893-e7ce-44b3-a9df-405ffd83148c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression model\n",
    "\n",
    "# Create training data\n",
    "x, y = [], []\n",
    "for i in train_set_x.index:\n",
    "    x.append(get_vector(vocabulary, train_set_x.loc[i, \"text\"]))\n",
    "    y.append(train_set_y.loc[i, \"label\"])\n",
    "\n",
    "# model\n",
    "svm_reg_model = LinearRegression()\n",
    "svm_reg_model.fit(np.asarray(x), np.asarray(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "773555eb-e172-495b-9329-11e2e2f14a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = [], []\n",
    "for i in val_set_x.index:\n",
    "    x.append(get_vector(vocabulary, val_set_x.loc[i, \"text\"]))\n",
    "    y.append(val_set_y.loc[i, \"label\"])\n",
    "predictions = svm_reg_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d5bcb64-6f1f-41c3-bac5-a53af80321d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2571765512839455\t1\n",
      "2.1569089034667903\t2\n",
      "0.9485102092747486\t0\n",
      "1.0588853992955987\t1\n",
      "1.2043833161405522\t1\n",
      "1.229522372110424\t1\n",
      "0.9515611863820803\t2\n",
      "0.9420238862628686\t0\n",
      "2.0244409253100626\t2\n",
      "1.2577483856932532\t1\n",
      "1.4198043813116326\t0\n",
      "1.842403257636192\t2\n",
      "1.296218335084969\t1\n",
      "1.1200345687171942\t1\n",
      "1.12048666405471\t0\n",
      "1.060987003030373\t2\n",
      "1.2591990328560405\t2\n",
      "0.7208669709067979\t1\n",
      "1.2578096820211415\t2\n",
      "0.4229060179281585\t0\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(str(predictions[i]) + \"\\t\" + str(y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44e7c383-e6bc-4ff8-9265-848b4f4c2d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '2', '0', '1', '1', '1', '2', '0', '2', '1', '0', '2', '1',\n",
       "       '1', '0', '2', '2', '1', '2', '0'], dtype='<U1')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17d6c3dc-f5a2-4747-b14e-cbe7e6dc3238",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(\u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmacro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(recall_score(y, predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(f1_score(y, predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1757\u001b[0m, in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision_score\u001b[39m(\n\u001b[0;32m   1629\u001b[0m     y_true,\n\u001b[0;32m   1630\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1636\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1637\u001b[0m ):\n\u001b[0;32m   1638\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[0;32m   1639\u001b[0m \n\u001b[0;32m   1640\u001b[0m \u001b[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[38;5;124;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m     p, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1762\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1764\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1766\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1767\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1544\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1544\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1547\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1348\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1346\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[1;32m-> 1348\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1351\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "print(str(precision_score(y, predictions, average='macro')))\n",
    "print(str(recall_score(y, predictions, average='macro')))\n",
    "print(str(f1_score(y, predictions, average='macro')))\n",
    "print(str(accuracy_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0f1ce4-a52b-4ede-a3fe-01fc8f64d3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f80f7c-eb71-4ebc-8253-018334be18e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf0fcda7-7f7b-4b16-8d91-a57159895f08",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "442f0421-1635-4545-aef2-fdc61dcc3ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6687085346069246\n",
      "0.6222323738146524\n",
      "0.6365109146172074\n",
      "0.674\n"
     ]
    }
   ],
   "source": [
    "# Initialize Tfidf Vectorizer\n",
    "tfidf_vector = TfidfVectorizer()\n",
    "# Learn vocabulary and idf from training set\n",
    "tfidf_vector.fit(train_set_x[\"text\"])\n",
    "# Transform train and test input documents to document-term matrix\n",
    "tfidf_train_x = tfidf_vector.transform(train_set_x[\"text\"])\n",
    "tfidf_val_x  = tfidf_vector.transform(val_set_x[\"text\"])\n",
    "\n",
    "# Train the classifier\n",
    "svm_clf_category.fit(tfidf_train_x, train_set_y.iloc[:,-1].to_numpy())\n",
    "# Test with test data\n",
    "predictions = svm_clf_category.predict(tfidf_val_x)\n",
    "tfidf_val_y = val_set_y.to_numpy()\n",
    "    \n",
    "print(str(precision_score(tfidf_val_y, predictions, average='macro')))\n",
    "print(str(recall_score(tfidf_val_y, predictions, average='macro')))\n",
    "print(str(f1_score(tfidf_val_y, predictions, average='macro')))\n",
    "print(str(accuracy_score(tfidf_val_y, predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23859801-9b2f-4f45-8400-46b6c1a82c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.598364428981503\n",
      "0.5654939929988184\n",
      "0.5680575073372092\n",
      "0.5944317811787692\n"
     ]
    }
   ],
   "source": [
    "tfidf_test_x  = tfidf_vector.transform(test_set_x[\"text\"])\n",
    "predictions = svm_clf_category.predict(tfidf_test_x)\n",
    "tfidf_test_y = test_set_y.to_numpy()\n",
    "print(str(precision_score(tfidf_test_y, predictions, average='macro')))\n",
    "print(str(recall_score(tfidf_test_y, predictions, average='macro')))\n",
    "print(str(f1_score(tfidf_test_y, predictions, average='macro')))\n",
    "print(str(accuracy_score(tfidf_test_y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e0845d-ddc4-4d6a-9e01-d8dd5020294a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
