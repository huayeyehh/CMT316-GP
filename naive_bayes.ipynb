{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37fe0fd6-0b6a-4463-84cf-9ead122f6c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import operator\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a69ea43-5ee4-470b-9aa6-aa0e187985ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from txt\n",
    "def read_data(set_name):\n",
    "    text_file_name  = set_name + \"_text.txt\"\n",
    "    label_file_name = set_name + \"_labels.txt\"\n",
    "    text_file = open(\"data/\" + text_file_name, \"r\", encoding=\"utf8\")\n",
    "    label_file = open(\"data/\" + label_file_name, \"r\", encoding=\"utf8\")\n",
    "    x = text_file.readlines()\n",
    "    y = label_file.readlines()\n",
    "    for i in range(len(y)): y[i] = y[i][0]\n",
    "    return pd.DataFrame(x, columns=[\"text\"]), pd.DataFrame(y, columns=[\"label\"])\n",
    "train_set_x, train_set_y = read_data(\"train\")\n",
    "val_set_x,   val_set_y   = read_data(\"val\")\n",
    "test_set_x,  test_set_y  = read_data(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d517060-ae1e-4a7a-bad9-8c8d69dd7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(vocab, text):\n",
    "    vector = np.zeros(len(vocab))\n",
    "    words = []\n",
    "    for sentence in nltk.tokenize.sent_tokenize(text):\n",
    "        for token in nltk.tokenize.word_tokenize(sentence):\n",
    "            words.append(lemmatizer.lemmatize(token).lower())\n",
    "    for i, word in enumerate(vocab):\n",
    "        if word in words:\n",
    "            vector[i] = words.count(word)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e85dca12-16f6-4eb2-af0d-1952b22f4e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label mapping declaration\n",
    "SENTIMENTAL_MAP = {\n",
    "    \"0\": \"negative\",\n",
    "    \"1\": \"neutral\",\n",
    "    \"2\": \"positive\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31c2a2db-2fa6-46bd-8a04-f70cab2715a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Feature: n most frequent words of each label class and combining them together\n",
    "# define stopwords\n",
    "stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "additional_stopwords = [\".\", \",\", \"'s\", \"``\", \"''\", \"'\", \"n't\", \"%\", \"-\", \"$\", \"(\", \")\", \":\", \";\", \"@\", \"&\", \"'m\", \"user\", \"#\", \"!\", \"?\", \"...\"]\n",
    "for sw in additional_stopwords: stopwords.add(sw)\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "# Get Vocabulary\n",
    "vocabulary = []\n",
    "n = 100\n",
    "for label in SENTIMENTAL_MAP.keys():\n",
    "    # get texts with same label\n",
    "    temp_list = []\n",
    "    for i in train_set_x.index:\n",
    "        if train_set_y.loc[i, \"label\"] == label:\n",
    "            temp_list.append(train_set_x.loc[i, \"text\"])\n",
    "    \n",
    "    # get n most frequent words of this label class\n",
    "    dict_word_freq = {}\n",
    "    for text in temp_list:\n",
    "        for sentence in nltk.tokenize.sent_tokenize(text):\n",
    "            for token in nltk.tokenize.word_tokenize(sentence):\n",
    "                word = lemmatizer.lemmatize(token).lower()\n",
    "                if word in stopwords: continue\n",
    "                if word in dict_word_freq: dict_word_freq[word] += 1\n",
    "                else: dict_word_freq[word] = 1\n",
    "                \n",
    "    # sort and add first n words in sorted list to vocabulary\n",
    "    sorted_list = sorted(dict_word_freq.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    if n < len(sorted_list): sorted_list = sorted_list[:n]\n",
    "    for word, frequency in sorted_list:\n",
    "        if word not in vocabulary: vocabulary.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a316864-747a-4e80-8b76-eab1e3e4780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "x, y = [], []\n",
    "for i in train_set_x.index:\n",
    "    x.append(get_vector(vocabulary, train_set_x.loc[i, \"text\"]))\n",
    "    y.append(train_set_y.loc[i, \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34571f16-8593-4eb4-972e-3b9bbeb51d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.fit(np.asarray(x), np.asarray(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c27b1d25-00c7-461a-84af-eaa18abfad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "vx, vy = [], []\n",
    "for i in val_set_x.index:\n",
    "    vx.append(get_vector(vocabulary, val_set_x.loc[i, \"text\"]))\n",
    "    vy.append(val_set_y.loc[i, \"label\"])\n",
    "predictions = gnb.predict(vx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a8b06bf-97f8-4dd3-8923-36a8b43aa6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5000896186203714\n",
      "0.5005342758507315\n",
      "0.49679783626740553\n",
      "0.531\n"
     ]
    }
   ],
   "source": [
    "print(str(precision_score(vy, predictions, average='macro')))\n",
    "print(str(recall_score(vy, predictions, average='macro')))\n",
    "print(str(f1_score(vy, predictions, average='macro')))\n",
    "print(str(accuracy_score(vy, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d1bbc9-0600-4596-9abb-507a30a1efe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726980d7-3885-493b-b655-db43c7c959bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
